# import pandas as pd
# from torch import nn
# from sklearn.model_selection import train_test_split
# import torch.optim as optim
# from sklearn.preprocessing import MinMaxScaler
# from torch.utils.data import DataLoader,TensorDataset
# import torch.nn.functional as F
# import torch
# SAMPLE_SIZE=1079
# ITERATIONS=40
# device=torch.device("cuda" if torch.cuda.is_available() else "cpu")
# df=pd.read_csv('/home/virtual/Desktop/MLforEE/projekt_maldetect/data/dynamic_api_call_sequence_per_malware_100_0_306.csv')
# mal_df=df[df['malware']==1]
# ben_df=df[df['malware']==0]

# X=df.iloc[:,1:101].values
# y=df.iloc[:,-1].values
# Xtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=0.3)

# Xt=torch.tensor(Xtrain)
# Xv=torch.tensor(Xtest)
# yt=torch.tensor(ytrain)
# yv=torch.tensor(ytest)

# traindataset=TensorDataset(Xt,yt)
# testdataset=TensorDataset(Xv,yv)
# criterion=nn.BCEWithLogitsLoss()

# train_loader = DataLoader(traindataset, batch_size=164, shuffle=True)
# test_loader = DataLoader(testdataset, batch_size=164, shuffle=False)

# num_epochs = 100

import pandas as pd
from torch import nn
from sklearn.model_selection import train_test_split
import torch
from torch.utils.data import DataLoader, TensorDataset
import torch.nn.functional as F

# --- Parameters ---
SAMPLE_SIZE = 1079
ITERATIONS = 40
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- Load Data ---
df = pd.read_csv('/home/virtual/Desktop/MLforEE/projekt_maldetect/data/dynamic_api_call_sequence_per_malware_100_0_306.csv')

X = df.iloc[:, 1:101].values   # 100 features
y = df.iloc[:, -1].values      # malware labels (0 or 1)

# --- Train/Test Split ---
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=42)

# --- Convert to Tensors ---
# Reshape to (batch_size, sequence_length, feature_dim_per_step)
# We can treat each feature as one time step with 1 feature value
Xt = torch.tensor(Xtrain).float().unsqueeze(-1)  # shape: (N, 100, 1)
Xv = torch.tensor(Xtest).float().unsqueeze(-1)
yt = torch.tensor(ytrain).float()
yv = torch.tensor(ytest).float()

traindataset = TensorDataset(Xt, yt)
testdataset = TensorDataset(Xv, yv)

train_loader = DataLoader(traindataset, batch_size=164, shuffle=True)
test_loader = DataLoader(testdataset, batch_size=164, shuffle=False)

# --- Define RNN Model ---
class SimpleRNN(nn.Module):
    def __init__(self, input_size=1, hidden_size=64, num_layers=1):
        super(SimpleRNN, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers

        self.rnn = nn.RNN(
            input_size=input_size, 
            hidden_size=hidden_size, 
            num_layers=num_layers, 
            batch_first=True
        )
        self.fc = nn.Linear(hidden_size, 1)  # binary output

    def forward(self, x):
        # Initialize hidden state (num_layers, batch, hidden_size)
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)

        # RNN output: (batch, seq_len, hidden_size)
        out, _ = self.rnn(x, h0)

        # Take the last time-step output
        out = out[:, -1, :]  # (batch, hidden_size)

        # Final fully connected layer
        out = self.fc(out)
        return out

# --- Initialize Model, Loss, Optimizer ---
model = SimpleRNN(hidden_size=100).to(device)
criterion = nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

# --- Training Loop ---
num_epochs = 75
best_accuracy=0.0
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0

    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs).squeeze()
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    avg_loss = running_loss / len(train_loader)
# --- Evaluation ---
    model.eval()
    correct = 0
    total = 0

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs).squeeze()
            predictions = torch.sigmoid(outputs) > 0.5
            correct += (predictions == labels).sum().item()
            total += labels.size(0)
    accuracy=100*correct/total
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        torch.save(model.state_dict(), "BestRNN.pth")    
    print(f"Epoch [{epoch+1}/{num_epochs}] | Loss: {avg_loss:.4f} | Val Accuracy: {accuracy:.2f}%")
print(f"✅ Accuracy: {100 * correct / total:.2f}%")

# --- Save Model ---
print(f"\n✅ Training complete! Best validation accuracy: {best_accuracy:.2f}%")
torch.save(model.state_dict(), "RNN_Classifier.pth")
